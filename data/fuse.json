{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Root","n":1},"1":{"v":"# Welcome to Dendron\n\nThis is the root of your dendron vault. If you decide to publish your entire vault, this will be your landing page. You are free to customize any part of this page except the frontmatter on top.\n\n## Lookup\n\nThis section contains useful links to related resources.\n\n- [Getting Started Guide](https://link.dendron.so/6b25)\n- [Discord](https://link.dendron.so/6b23)\n- [Home Page](https://wiki.dendron.so/)\n- [Github](https://link.dendron.so/6b24)\n- [Developer Docs](https://docs.dendron.so/)","n":0.132}}},{"i":2,"$":{"0":{"v":"Tools","n":1}}},{"i":3,"$":{"0":{"v":"Product End of Life","n":0.5},"1":{"v":"\nRetrouver facilement la fin de support des frameworks, langages ou autres produit :\n\nhttps://endoflife.date/\n\nlien rapide vers quelques produits:\n- java: https://endoflife.date/oracle-jdk\n- spring boot: https://endoflife.date/spring-boot\n- mongodb: https://endoflife.date/mongodb\n- postgres: https://endoflife.date/postgresql ","n":0.196}}},{"i":4,"$":{"0":{"v":"Keytool","n":1},"1":{"v":"\nVoir le certificat d'un site\n```Shell\nopenssl s_client -showcerts -connect google.fr:443\n```\n\n\nVoir la liste des clé dans un truststore\n```shell\nkeytool -list -v -keystore truststore.jks\n```\n","n":0.224}}},{"i":5,"$":{"0":{"v":"Intellij   Unused Code Detection","n":0.5},"1":{"v":"\nConfiguration dans Editor -> inspections -> Java -> Declaration redundancy -> Unused declaration\n\nNotes : Ne supprime pas le tag utilisé des méthodes utilisées que dans les tests\n\n--- \n\nSource:\n- https://blog.jetbrains.com/idea/2016/09/intellij-idea-2016-3-eap-makes-unused-code-detection-more-flexible/\n","n":0.186}}},{"i":6,"$":{"0":{"v":"Cron Validator","n":0.707},"1":{"v":"\nPetit validator en ligne pour se rappeler des crons : https://crontab.guru/\n\nexemple : \n```\n5 4 * * *\n```\n\n\nfield | value | alternative\n---------|----------|---------\n minute | 0-59 | \n heure | 0-23 | \n day of month | 1-31 | \n month | 1-12 | JAN-DEC\n day of week | 0-6 0=SUN | 7=SUN (non standard)\n\nSur certain expression cron du style quartz comprenant les secondes et l'année en dernière colonne.\n\n# Quelques tips :\n\nTip 1: If the day-of-month or day-of-week part starts with a *, they form an intersection. Otherwise they form a union. * * 3 * 1 runs on the 3rd day of the month and on Monday (union), whereas * * */2 * 1 runs on every second day of the month only if it's also a Monday (intersection). The [[manpage|https://crontab.guru/crontab.5.html]] is incorrect about this detail. More info.\n\n\nTip 2: Run your servers including the cron process in UTC timezone. [[Why?|http://yellerapp.com/posts/2015-01-12-the-worst-server-setup-you-can-make.html]]\n\nTip 3: Some cron implementations allow to specify years and seconds. However, cron is not the best tool if you need to operate at those levels, which is also why crontab.guru doesn't support them.\n\nTip 4: Don't use `@reboot` because it has too many [[issues|http://unix.stackexchange.com/questions/109804/crontabs-reboot-only-works-for-root]].\n\nTip 5: More difficult schedules can be realized by combining multiple cron expressions. For example, if you need to run X every 90 minutes, create one crontab entry that runs X every 3 hours on the hour (0 */3 * * *), and a second crontab entry that runs X every 3 hours with an offset (30 1/3 * * *).\n\n---\n\nSources : \n- https://crontab.guru/tips.html\n- http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html","n":0.063}}},{"i":7,"$":{"0":{"v":"Tags","n":1}}},{"i":8,"$":{"0":{"v":"Security","n":1}}},{"i":9,"$":{"0":{"v":"Programmation","n":1}}},{"i":10,"$":{"0":{"v":"Linux","n":1}}},{"i":11,"$":{"0":{"v":"Kubernetes","n":1}}},{"i":12,"$":{"0":{"v":"Java","n":1}}},{"i":13,"$":{"0":{"v":"Gpg","n":1}}},{"i":14,"$":{"0":{"v":"Git","n":1}}},{"i":15,"$":{"0":{"v":"Docker","n":1}}},{"i":16,"$":{"0":{"v":"Adminsys","n":1}}},{"i":17,"$":{"0":{"v":"TU","n":1}}},{"i":18,"$":{"0":{"v":"Programation","n":1}}},{"i":19,"$":{"0":{"v":"Java","n":1}}},{"i":20,"$":{"0":{"v":"Tu","n":1}}},{"i":21,"$":{"0":{"v":"Pitest Mutation De Test","n":0.5},"1":{"v":"\nMutation de test permet de valider que les tests sont efficace.\nMais l'execution est plus long\n\nMise en place de mutation de test avec pitest sur maven\n```xml\n<plugin>\n  <groupId>org.pitest</groupId>\n  <artifactId>pitest-maven</artifactId>\n  <version>1.7.1</version>\n  <!-- optional, this example attached the goal into mvn test phase\n  instead of launching mvn clean test org.pitest:pitest-maven:mutationCoverage\n  reports are found under target/pi-reports\n  -->\n  <executions>\n    <execution>\n      <id>pit-report</id>\n      <phase>test</phase>\n      <goals>\n        <goal>mutationCoverage</goal>\n      </goals>\n    </execution>\n  </executions>\n  <configuration>\n    <timestampedReports>false</timestampedReports>\n  </configuration>\n  <!-- https://github.com/hcoles/pitest/issues/284 -->\n  <!-- Need this to support JUnit 5 -->\n  <dependencies>\n    <dependency>\n      <groupId>org.pitest</groupId>\n      <artifactId>pitest-junit5-plugin</artifactId>\n      <version>0.15</version>\n    </dependency>\n  </dependencies>\n</plugin>\n```\n\n---\n\nSource:\n- https://pitest.org/quickstart/maven/\n","n":0.11}}},{"i":22,"$":{"0":{"v":"Organiser Un Tu","n":0.577},"1":{"v":"\nUn test unitaire est organise en 3 parties :\n\n```Java\n@Test\nvoid myTemplate() {\n  // Arrange\n\n  // Act\n\n  // Assert\n\n}\n```\n\nou\n\n```Java\n@Test\nvoid given_when_then() {\n  // Given\n\n  // When\n\n  // Then\n\n}\n```\n\nplus proche des critères d'acceptation\n\n","n":0.186}}},{"i":23,"$":{"0":{"v":"Customiser Les Noms Des Tu","n":0.447},"1":{"v":"\nPour rendre la rapport de test plus lisible déjà améliorer par une convention de nommage inspiré du clean code [[programation.java.tu.convention-de-nommage]]\n\nPossible de customiser en remplacement les underscore par des espaces : \n```\n@DisplayNameGeneration(DisplayNameGenerator.ReplaceUnderscores.class)\nclass ReplaceUnderscoresGeneratorUnitTest {\n\n    @Nested\n    class when_doing_something {\n\n        @Test\n        void then_something_should_happen() {\n        }\n\n        @Test\n        @DisplayName(\"@DisplayName takes precedence over generation\")\n        void override_generator() {\n        }\n    }\n}\n```\n--- \n\nSource:\n- https://www.baeldung.com/junit-custom-display-name-generator\n","n":0.135}}},{"i":24,"$":{"0":{"v":"Convention De Nommage","n":0.577},"1":{"v":"2023-02-12\n\nNommer le TU pour avoir le sens dans le nom plutôt que la méthode.\nNom pour une feature: \n`Should_ExpectedBehavior_When_StateUnderTest`\nOu \n`When_StateUnderTest_Expect_ExpectedBehavior`\n\nLa création de TU pour une feature en fonction d'un état peut se créer de manière interactive par la [[méthode-tdd]]\n\n---\n\nSource:\n- https://cleantestcode.wordpress.com/2014/05/03/names-should-be-expressive-when-writing-tests/\n","n":0.16}}},{"i":25,"$":{"0":{"v":"Type De Mémoire en Java","n":0.447},"1":{"v":"\n# heap memory\n\nMémoire principale, contenant les objets créé par l'application.\n\nConfigurable par le -Xms et -Xmx exemple \n`java -Xms4096M -Xmx6144M ClassName`\n\nJava utilise un Garbage collector pour le nettoyage de la heap : [[programation.java.garbage-collector]]\n\n# Stack memory \n\nStock les variables locale et les informations de méthode mais aussi les thead exécution \n\nIl n'est pas géré par les Garbage collector mais par la jvm directement.\n\n\n# Native Memory\n\nL'allocation de mémoire a l'extérieur de la heap java et utilisé par la jvm.\nAussi appelé off-heap memory\n\nUtilisé pour réaliser le serialisation en lecture et écriture. \nLes performances dépend du buffer, du process de serialisation et de l'espace disque \n\nLa JVM stock les stack de thread, les données Internet and memory mapped files.\n\n# Direct Memory\n\nAllocation en dehors de la java heap.\nÇa représente la mémoire utilisé sur l'OS par le process de la JVM.\n\nJava NIO utilisé cette mémoire pour écrire les données sur le réseau ou le disques\n\nOn peut limiter le direct buffer memory size en utilisant ce paramètre :\n`-XX:MaxDirectMemorySize=1024M`\n\n--- \nTags: #java\n\nSource:\n- Memory Types in JVM https://www.baeldung.com/java-jvm-memory-types","n":0.077}}},{"i":26,"$":{"0":{"v":"Garbage Collector Java","n":0.577},"1":{"v":"\nLe Garbage collector permet de nettoyer une partie de la mémoire de l'application. Au niveau de la heap.\n[[programation.java.type-de-memoire]] \n\n# Mémoire Heap\nLa heap est divisée en deux zones :\n**Young generation** : zone jeune est l'endroit où les objets nouvellement créés sont stockés. Encore devisé en deux \"Eden Space\" et \"survivor spaces\". Les objets qui sont conservées dans la young generation est promu dans la old generation.\n**Old generation** : zone de stockage long, où les objets ont survécu à plusieurs cycle de collection dans la young generation.\nLa zone est aussi subdivisé en deux espaces, l'espace permanent \"permanent space\" et l'espace de la pile \"stack memory \"\n\n# type de collector \n- **Serial GC**, GC par défaut pour les applications a faible consommation de mémoire, monothread. La collecte est relativement simple. `-XX:+UseSerialGC`\n- **Parallel GC**, pour les applications a forte consommation de mémoire, multithreads. La collecte exécuter en parallèle sur plusieurs thread pour améliorer les performances. `-XX:+UseParallelGC`\n- **Concurrent-Mark sweep GC**, pour les applications avec des temps de réponse rapide, ou la latence est un facteur critique. La collecte fonctionne en arrière plan pour minimiser la durée de la pause de collection. `-XX:+UseConcMarkSweepGC`\n- **Garbage-First GC (G1)**, pour les applications a forte consommation mémoire et contrainte de temps de réponse strictes. Fonctionne en parallèle sur plusieurs thread pour les performances utilisé aussi un tri de tas pour optimiser les performances. `-XX:+UseG1GC`\n\n# Fonctionnement du Garbage collector\nLe GC s'exécute en arrière plan, à la recherche des objets plus référencés par le programme et les marque pour la suppression.\nLe traitement de nettoyage est déclenché lorsque la JVM détecte que l'espace disponible sur le tas est devenu insuffisant pour allouer de nouveau objet.\n\nDans la zone jeune, la stratégie de GC se base sur le comptage de référence dans l'application.\nUne fois qu'un objet n'est plus référencé, le GC les marques comme objet à supprimer.\nUne fois un objet a survécu à plusieurs cycles, l'objet est promu à la zone ancienne.\n\nDans la zone ancienne, le GC utilise une stratégie de marque et de balayage. \nCette stratégie marque tous les objets encore référencés, puis balayage la mémoire pour supprimer les objets non marqué.\nCette stratégie peu engendrer une pause dans la JVM ce qui peut affecter les performances.\n\nLes performances du GC depends de beaucoup de facteur comme la taille de l'application, le nombre d'allocations, le nombre de thread.\n\nDes tests de performances sont a effectué pour attribuer la meilleure stratégie de GC.\n\n---\n\nSource:\n- https://kotlin-java.fr/garbage-collector-jvm/","n":0.05}}},{"i":27,"$":{"0":{"v":"Execute Heapdump","n":0.707},"1":{"v":"Prérequis : exécuter un garbage collector pour vider la mémoire afin de mieux détecter un memory leak [[programation.java.execute-garbage-collector]]\n\nInto docker :\n\n`jmap -dump:format=b,file=<filename>`\n\nOr\n\n`jcmd <PID> GC.heap_dump -all dump`\n\n","n":0.2}}},{"i":28,"$":{"0":{"v":"Execute Garbage Collector","n":0.577},"1":{"v":"Vide la mémoire des références d'objet non utilisé :\n\n`jcmd <PID> GC.run`\n\n","n":0.302}}},{"i":29,"$":{"0":{"v":"Principe Solid","n":0.707},"1":{"v":"\n# Single responsibility principle\nFaire une chose et la faire bien \n\n\n# Open closed principle\nOuvert a l'extension \nFermé a a modification\n\n\n# Liskov substitution principle\n\nune super-class peut être remplacer par une sous-class.\n\nAjout d'interface/class intermédiaire ?\n\n# Interface segregation principle\n\nDéfinition d'interface cohérent de méthode pour ne pas a avoir à implémenté des méthodes qu'on n'utilise pas.\n\n# Dependency inversion principle\n\nModule de haut niveau ne doit pas dépendre des modules de bas niveau\n\n\n---\n\nSource:\n- https://filippobuletto.github.io/solid-java\n- https://blog.xebia.fr/2011/07/18/les-principes-solid/\n- https://devopedia.org/solid-design-principles\n- https://itnext.io/solid-principles-explanation-and-examples-715b975dcad4\n- https://dev.to/arpitmandliya/a-guide-to-solid-principles-in-java-17ne\n","n":0.118}}},{"i":30,"$":{"0":{"v":"Methode Tdd","n":0.707},"1":{"v":"\n3 étapes :\n- RED : écriture du test qui fail\n- Green : écrire le code minimal pour faire passer le test\n- Refacto : \n    - compréhensible\n    - optimisé\n    - flexible\n    - maintenable\n    - réutilisable\n    - évolutif\n\n## Les 4 lois TDD :\n\n1.  Ne pas écrire un code de production tant qu’un test unitaire d’échec n’a pas été écrit ;\n2.  Il faut uniquement écrire le test unitaire suffisant pour échouer ;\n3.  Il faut uniquement écrire le code de production suffisant pour rendre opérationnel le test d’échec courant ;\n4.  Il faut remanier le code de production.\n\n\n---\n\nSource:\n- https://www.baeldung.com/java-test-driven-list\n","n":0.103}}},{"i":31,"$":{"0":{"v":"K8s","n":1}}},{"i":32,"$":{"0":{"v":"Upgrade Argocd","n":0.707},"1":{"v":"\n`<version>` correspond au tag argocd comme `v2.6.1`\n\n# Non-HA\n\n```Shell\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/<version>/manifests/install.yaml\n```\n\n# HA\n\n```Shell\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/<version>/manifests/ha/install.yaml\n```\n\n---\n\nSource:\n- https://argo-cd.readthedocs.io/en/stable/operator-manual/upgrading/overview/\n","n":0.224}}},{"i":33,"$":{"0":{"v":"Longhorn Installation","n":0.707},"1":{"v":"\n# Pré-requis\n\n```bash\napt-get install open-iscsi nfs-common\n```\n\n--- \n\nSource:\n- https://longhorn.io/docs/1.4.3/deploy/install/#installing-open-iscsi\n- https://longhorn.io/docs/1.5.1/deploy/install/#installing-nfsv4-client","n":0.354}}},{"i":34,"$":{"0":{"v":"Kustomize Template to Customize Application Configuration","n":0.408},"1":{"v":"\nKustomize aide a configurer l'application en étant libre sur les modèles de template\nPermet la création de patch pour un environnement sans modifier la base de déploiement.\n\n--- \n\nSource:\n- https://kustomize.io/\n- https://www.grottedubarbu.fr/kubernetes-kustomize-traefik/","n":0.186}}},{"i":35,"$":{"0":{"v":"Kuik Cache D Image","n":0.5},"1":{"v":"\nOutis open source, pour réaliser du cache d'image docker directement sur le cluster.\n\nSélecteur sur le noeud controle-plan qui gère le cluster.\nLimite le pull des images sur les registry publiques. Afin de gérer l'indispo du registry ou la suppression des images ou de ne pas dépasser les limites de pull.\n\n1er version en 2022.\n\n--- \n\nSource:\n- https://enix.io/fr/blog/caching-image-conteneurs-kubernetes/\n- https://github.com/enix/kube-image-keeper","n":0.135}}},{"i":36,"$":{"0":{"v":"Kubectl Config Context","n":0.577},"1":{"v":"\n# changement de context \n```Shell\nkubectl config use-context <context-name>\n```\n\n\n# création d'un cluster\n```shell\nkubectl config --kubeconfig=config-demo set-cluster development --server=https://1.2.3.4 --certificate-authority=fake-ca-file\n```\n\n# création d'un credentials\n```shell\nkubectl config --kubeconfig=config-demo set-credentials developer --client-certificate=fake-cert-file --client-key=fake-key-seefile\n```\n\n# création d'un context\n```shell\nkubectl config --kubeconfig=config-demo set-context dev-storage --cluster=development --namespace=storage --user=developer\n```\n\n# suppression de context \n- To delete a user you can run `kubectl --kubeconfig=config-demo config unset users.<name>`\n- To remove a cluster, you can run `kubectl --kubeconfig=config-demo config unset clusters.<name>`\n- To remove a context, you can run `kubectl --kubeconfig=config-demo config unset contexts.<name>`\n\n\n---\n\nSource:\n- https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\n- https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/","n":0.113}}},{"i":37,"$":{"0":{"v":"K3s Install","n":0.707},"1":{"v":"\n## SERVER\n\n# Disable traefik\n```\nexport INSTALL_K3S_EXEC=\"server --disable=traefik --cluster-init\"\n```\n\n# Create k3s cluster\n```\ncurl -sfL https://get.k3s.io | K3S_TOKEN=\"SECRET\" sh -s - server --cluster-init\n```\n\nAjout d'un noeud serveur\n\n```\ncurl -sfL https://get.k3s.io | K3S_TOKEN=SECRET sh -s - server \\\n    --server https://<ip or hostname of server1>:6443 \n```\n## AGENT \n\n\n# Add server as a worker node\nRécupération du token  sur le serveur maitre:\n```\nsudo cat /var/lib/rancher/k3s/server/node-token\n```\n\nSur le future node :\n```\ncurl -sfL https://get.k3s.io | K3S_TOKEN=\"SECRET\" sh -s - agent --server https://IP_SERVER_MASTER:6443\n```\n\n--- \n\nSource:\n- https://docs.k3s.io/quick-start\n- https://docs.k3s.io/datastore/ha-embedded","n":0.119}}},{"i":38,"$":{"0":{"v":"Dashboard Kubernetes","n":0.707},"1":{"v":"\n# Configuration du service Account\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kubernetes-dashboard\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kubernetes-dashboard\n\n```\n\n# create token \n\n```\nkubectl -n kubernetes-dashboard create token admin-user\n```\n\n# clear security\n\n```\nkubectl -n kubernetes-dashboard delete serviceaccount admin-user\nkubectl -n kubernetes-dashboard delete clusterrolebinding admin-user \n```\n\n\n# Web Access \n## Command line proxy\n\nYou can enable access to the Dashboard using the `kubectl` command-line tool, by running the following command:\n\n```\nkubectl proxy\n```\n\nKubectl will make Dashboard available at [http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/](http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/).\n\n---\n\nSource:\n- https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/","n":0.113}}},{"i":39,"$":{"0":{"v":"Gpg","n":1}}},{"i":40,"$":{"0":{"v":"Vérification Des Clés Gpg Existantes","n":0.447},"1":{"v":"\n# Liste les clés existantes\n\n```shell\ngpg --list-secret-keys --keyid-format=long\n```\n\nPossible de faire de la récupération de clé publique : [[gpg.récupération-de-la-clé-publique]]\nou de régénérer une nouvelle clé [[gpg.génération-d un-nouvelle-clé-gpg]]\n\n---\n\nSource:\n- https://git-scm.com/book/fr/v2/Utilitaires-Git-Signer-votre-travail\n- https://docs.github.com/fr/authentication/managing-commit-signature-verification/checking-for-existing-gpg-keys\n","n":0.196}}},{"i":41,"$":{"0":{"v":"Récupération De La Clé Publique","n":0.447},"1":{"v":"\n\n```shell\ngpg --armor --export ID\n```\n\n\n---\n\nSource:\n- https://docs.github.com/fr/authentication/managing-commit-signature-verification/checking-for-existing-gpg-keys\n\n","n":0.447}}},{"i":42,"$":{"0":{"v":"Génération D Un Nouvelle Clé Gpg","n":0.408},"1":{"v":"\nSi vous utilisez la version 2.1.17 ou une version ultérieure\n```shell\ngpg --full-generate-key\n```\n\nPossible de custom l'aglo :\n```shell\ngpg --default-new-key-algo rsa4096 --gen-key\n```\n\n\n---\n\nRelated:\n- [[gpg.vérification-des-clés-gpg-existantes]]\n\nSource:\n- https://docs.github.com/fr/authentication/managing-commit-signature-verification/generating-a-new-gpg-key\n","n":0.229}}},{"i":43,"$":{"0":{"v":"Git","n":1}}},{"i":44,"$":{"0":{"v":"Signer Ces Commits","n":0.577},"1":{"v":"\nprérequis : \n- Avoir l'ID de la clé gpg [[gpg.vérification-des-clés-gpg-existantes]]\n- connaitre la clé public gpg [[gpg.récupération-de-la-clé-publique]]\n\nAjout au config git \n```Shell\ngit config --global user.signingkey ID\n```\n\nForce la signature des commits\n```Shell\ngit config --global commit.gpgsign true\n```\n\n\n--- \n\nSource:\n- https://git-scm.com/book/fr/v2/Utilitaires-Git-Signer-votre-travail\n- https://docs.github.com/fr/authentication/managing-commit-signature-verification/telling-git-about-your-signing-key\n- https://docs.github.com/fr/authentication/managing-commit-signature-verification/adding-a-gpg-key-to-your-github-account\n","n":0.167}}},{"i":45,"$":{"0":{"v":"Rebase Branche to Change Base Branch","n":0.408},"1":{"v":"\n2023-03-10\n\nGit permet de réécrire l'historique avec un rebase de déplacer une branche vers une autre. Ce cas d'usage peut-être utile pour déplacer une feature d'une branche de support vers une autre version a cause d'un changement de périmètre.\n\nCe changement peut se réaliser en une simple ligne de command :  \n\n``` Shell\ngit rebase --onto $targetBranch $fromBranch $featureBranch\n```\n\n- `$targetBranch` : la branche de destination sur lequel les commits seront rejoués\n- `$fromBranch` : la branche de base des commits à rejouer, les commits de cette branche seront exclus\n- `$featureBranch` : la branche contenant les commits qui vont être rejoués\n\n---\n\nSource:\n- https://git-scm.com/book/fr/v2/Les-branches-avec-Git-Rebaser-Rebasing","n":0.102}}},{"i":46,"$":{"0":{"v":"Modifier L Auteur D Un Commit","n":0.408},"1":{"v":"\n# Remplacer un user un autre utilisateur\n\n``` Shell\ngit filter-branch --env-filter '\nOLD_EMAIL=\"your-old-email@example.com\"\nCORRECT_NAME=\"Your Correct Name\"\nCORRECT_EMAIL=\"your-correct-email@example.com\"\nif [ \"$GIT_COMMITTER_EMAIL\" = \"$OLD_EMAIL\" ]\nthen\n    export GIT_COMMITTER_NAME=\"$CORRECT_NAME\"\n    export GIT_COMMITTER_EMAIL=\"$CORRECT_EMAIL\"\nfi\nif [ \"$GIT_AUTHOR_EMAIL\" = \"$OLD_EMAIL\" ]\nthen\n    export GIT_AUTHOR_NAME=\"$CORRECT_NAME\"\n    export GIT_AUTHOR_EMAIL=\"$CORRECT_EMAIL\"\nfi\n' --tag-name-filter cat -- --branches --tags\n\ngit filter-repo --mailmap git-mailmap\n```\n# Reset les informations pour un commit HEAD\n\n``` Shell\ngit commit --amend --no-edit --reset-author\n```\n\n# Rebase l'historique \n\n```Shell\ngit rebase -r <some commit before all of your bad commits> \\\n    --exec 'git commit --amend --no-edit --reset-author'\n```\n\n`-r root` pour l'ensemble de l'historique \n\n---\n\nSource:\n- [Stackoverflow - rebase with me](https://stackoverflow.com/a/1320317)\n","n":0.11}}},{"i":47,"$":{"0":{"v":"Delete Branch","n":0.707},"1":{"v":"2023-02-02\n\nSuppression des branches en local :\n```Shell\ngit branch -d maBranche\n```\n\nSuppession des branches en remote :\n```Shell\ngit push origin --delete maBranche\n```\n\nAccepte d'avoir plusieurs branches en une seule commande\n\n--- \n\nSource:\n- https://git-scm.com/book/en/v2/Git-Branching-Branch-Management\n- https://git-scm.com/docs/git-branch\n","n":0.189}}},{"i":48,"$":{"0":{"v":"Formation","n":1}}},{"i":49,"$":{"0":{"v":"Formation Aws Developper","n":0.577},"1":{"v":"# Embarquement\n \n1. Récupérez les slides ici (c’est plus pratique pour vous – attention, il s’agit d’une copie personnelle) [https://load-public.s3-eu-west-3.amazonaws.com/awsdev.zip](https://load-public.s3-eu-west-3.amazonaws.com/awsdev.zip)\n1. Ramp up Guide Développer [https://d1.awsstatic.com/training-and-certification/ramp-up_guides/Ramp-Up_Guide_Developer.pdf](https://d1.awsstatic.com/training-and-certification/ramp-up_guides/Ramp-Up_Guide_Developer.pdf)\n1. Guide et informations sur l’examen de certification https://aws.amazon.com/fr/certification/certified-developer-associate/?ch=tile&tile=getstarted\n1. Récupérer les slides de préparation à la certification https://load-public.s3-eu-west-3.amazonaws.com/aws-dev-cert-GK4504Prep.zip\n1. Conditionnez-vous aux réelles questions de l’examen https://www.examtopics.com/exams/amazon/aws-certified-developer-associate/\n\n## Resources\n\n![wich aws conatiner service should I user ?](assets/images/aws-whichContainerServiceShouldIuse.png)\n\n![datastoreChoices](assets/images/aws-datastoreChoices.png)\n\nDéveloppeurs multi-platforms Cloud (équivalences)\n\n[https://comparecloud.in/](https://comparecloud.in/)\n\nBonnes pratiques pour le développement Agile\n\n[https://12factor.net/](https://12factor.net/)\n\nDesign 100% Cloud (Fan-Out, Request Offloading, Circuit Breaker, etc)\n\n[https://www.microsoft.com/en-us/download/details.aspx?id=42026](https://www.microsoft.com/en-us/download/details.aspx?id=42026)\n\nFun : Résistance du code AWS Fault Injector Simulator\n\n[https://aws.amazon.com/fr/fis/](https://aws.amazon.com/fr/fis/)\n\nAnalyse économique du code Amazon Code Guru (Java ou Python)\n\n[https://aws.amazon.com/fr/codeguru/](https://aws.amazon.com/fr/codeguru/)\n\n## Plus loin\n\nAWS SAM : Template la création des applications.\n\nAPI, lambda, …\n","n":0.1}}},{"i":50,"$":{"0":{"v":"Docker","n":1}}},{"i":51,"$":{"0":{"v":"Docker privilege escalation","n":0.577},"1":{"v":"\n# Les dangers du groupe docker\n\nSi un utilisateur a le groupe docker alors il a toutes les droits sur la machine.\nil peut utiliser un container du genre alpine ou ubuntu pour remonter le systeme en mode root \n\n```bash\ndocker run --rm -it -u root --privileged -v /:/mnt -v /var:/mnt/var -v /home/:/mnt/home ubuntu:22.04 chroot /mnt /bin/bash\n```\n\n---\nSources:\n- https://blog.creekorful.org/2020/08/docker-privilege-escalation/","n":0.135}}},{"i":52,"$":{"0":{"v":"Docker Clean Useless Image","n":0.5},"1":{"v":"\n# Remove all images without tags :\n```Shell\ndocker rmi $(docker images -f \"dangling=true\" -q)\n```\n\n# cleanup images unsused :\n```Shell\ndocker image prune -a\n```\nPossible d'ajouter un filtre exemple créé il y a plus de 24h :\n`--filter \"until=24h\"`\n\n--- \n\nSource:\n- https://docs.docker.com/config/pruning/\n\n","n":0.169}}},{"i":53,"$":{"0":{"v":"Adminsys","n":1}}},{"i":54,"$":{"0":{"v":"Ubuntu Mise À Jour Automatique","n":0.447},"1":{"v":"\nUtilisation du package unattended-upgrades\n\n```\napt install unattended-upgrades\n```\n\n\n\n--- \n\nSource:\n- https://guide.ubuntu-fr.org/server/automatic-updates.html","n":0.354}}},{"i":55,"$":{"0":{"v":"Ssh Ajout D Une Clé D Authorisation","n":0.378},"1":{"v":"\n# Installation via ligne de commande\n\n\n```\nssh-copy-id -i ~/.ssh/id_rsa.pub YOUR_USER_NAME@IP_ADDRESS_OF_THE_SERVER\n```\n\n--- \n\nSource:\n- https://linuxhandbook.com/add-ssh-public-key-to-server/\n- https://linuxopsys.com/topics/ssh-copy-id-command","n":0.289}}},{"i":56,"$":{"0":{"v":"Information Disk Lvm","n":0.577},"1":{"v":"Affichage des groupes de volumes\n\n`vgdisplay`\n\nexemple de sortie:\n```\n# vgdisplay new_vg\n  --- Volume group ---\n  VG Name               new_vg\n  System ID\n  Format                lvm2\n  Metadata Areas        3\n  Metadata Sequence No  11\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                1\n  Open LV               0\n  Max PV                0\n  Cur PV                3\n  Act PV                3\n  VG Size               51.42 GB\n  PE Size               4.00 MB\n  Total PE              13164\n  Alloc PE / Size       13 / 52.00 MB\n  Free  PE / Size       13151 / 51.37 GB\n  VG UUID               jxQJ0a-ZKk0-OpMO-0118-nlwO-wwqd-fD5D32\n  ```\n\naffiche les groupes volumes en compact\n`vgs` \n\nlien:\n- [[adminsys.ajout-d-espace-disk]]\n","n":0.106}}},{"i":57,"$":{"0":{"v":"Firewall with Iptables","n":0.577},"1":{"v":"\n# autoriser le trafic local \n\n```bash\niptables -A INPUT -i lo -j ACCEPT\n```\n# autoriser le trafic sur un port spécifique\n\n```bash\niptables -A INPUT -p tcp --dport 80 -j ACCEPT\n```\n\n# supprimer le trafic indésirable\nAjout d'une règle strict a inserer en dernier\n```bash\niptables -A INPUT -j DROP\n```\nChangement de policy pour refuser le trafic si aucune règle fonctionne \n```\niptables --policy INPUT DROP\n```\n\n# supprimer une règle\n```bash\niptables -D INPUT <Number>\n```\n\n# enregistrer vos modifications\n\nSauvegarder les règles pour les conserver lors du reboot\n\n```bash\niptables-save -c\n```\n\n\n\n--- \n\nSource:\n- https://help.ovhcloud.com/csm/fr-dedicated-servers-firewall-iptables?id=kb_article_view&sysparm_article=KB0043442","n":0.115}}},{"i":58,"$":{"0":{"v":"Fail2ban   Auto Ban","n":0.577},"1":{"v":"2023-08-05\n\n\n```shell\napt install fail2ban\n```\n\n---\n\nSource:\n- https://doc.ubuntu-fr.org/fail2ban","n":0.5}}},{"i":59,"$":{"0":{"v":"Ajout d'espace disk","n":0.577},"1":{"v":"\nAjouter 10 Go sur la partition \n`lvextend -L10G /dev/mapper/{name-disk}`\n\nAppliquer le resize sur la parition \n`resize2fs /dev/mapper/{name-disk}`\n\nlien :\n- [[adminsys.information-disk-lvm]] : récupération des informations de la place disponnibe\n","n":0.196}}}]}
